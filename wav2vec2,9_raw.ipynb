{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKk+QP9rbhN/dpZP1HmwPe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nylee16/opensource_project/blob/main/wav2vec2%2C9_raw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jTHFD1tunhS"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "from datasets import load_dataset\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from jiwer import wer\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"kresnik/wav2vec2-large-xlsr-korean\")\n",
        "\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"kresnik/wav2vec2-large-xlsr-korean\").to('cuda')\n",
        "\n",
        "ds = load_dataset(\"kresnik/zeroth_korean\", \"clean\")\n",
        "\n",
        "test_ds = ds['test']\n",
        "\n",
        "def map_to_array(batch):\n",
        "    speech, _ = sf.read(batch[\"file\"])\n",
        "    batch[\"speech\"] = speech\n",
        "    return batch\n",
        "\n",
        "test_ds = test_ds.map(map_to_array)\n",
        "\n",
        "def map_to_pred(batch):\n",
        "    inputs = processor(batch[\"speech\"], sampling_rate=16000, return_tensors=\"pt\", padding=\"longest\")\n",
        "    input_values = inputs.input_values.to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = processor.batch_decode(predicted_ids)\n",
        "    batch[\"transcription\"] = transcription\n",
        "    return batch\n",
        "\n",
        "result = test_ds.map(map_to_pred, batched=True, batch_size=16, remove_columns=[\"speech\"])\n",
        "\n",
        "print(\"WER:\", wer(result[\"text\"], result[\"transcription\"]))\n"
      ]
    }
  ]
}